{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliMurtaza096/AliMurtaza096/blob/main/trump1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtr0QIqhKJuT",
        "outputId": "d3b49b78-b099-4f3f-be3f-182c3c424915"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z8FXdlbJDNjh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip3 install ffmpeg\n",
        "# !pip3 install pydub\n",
        "# !pip3 install matplotlib\n",
        "# !pip3 install torch\n",
        "# !pip3 install torchaudio\n",
        "# !pip3 install librosa\n",
        "# !pip3 install inflect\n",
        "# !pip3 install deep_phonemizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install deep_phonemizer\n"
      ],
      "metadata": {
        "id": "CgUycKkyXj1h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zq9jEXwDDNjk"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "# import os \n",
        "\n",
        "# file= open(\"wavs.txt\")\n",
        "# file = file.readlines()\n",
        "\n",
        "# for i, line in enumerate(file):\n",
        "#     filename = re.findall(r'\\d.wav.',line)\n",
        "#     pattern = filename[0]\n",
        "#     print(pattern)\n",
        "    \n",
        "#     replace = ''\n",
        "#     if i <=8:\n",
        "#         output_str = re.sub(\"\\d.wav|\", replace, line)\n",
        "#     elif i <=98:\n",
        "#         output_str = re.sub(\"\\d\\d.wav|\", replace, line)\n",
        "#     else:\n",
        "#         output_str = re.sub(\"\\d\\d\\d.wav|\", replace, line)\n",
        "#     output_str = output_str.replace(\"|\",\"\")\n",
        "#     print(output_str)\n",
        "#     path = os.path.join(\"/home/ali/Desktop/Namal/Idrak/trump/wavs_text\",f'{i+1}.txt')\n",
        "#     file = open(path,'w')\n",
        "#     file = file.write(output_str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YURX6raWDNjk"
      },
      "outputs": [],
      "source": [
        "# import inflect\n",
        "# import re\n",
        "\n",
        "            \n",
        "            \n",
        "           \n",
        "# def cleaning_text_files (dir_path): \n",
        "    \n",
        "#     paths = os.listdir(dir_path)\n",
        "#     p = inflect.engine()\n",
        "#     count = 0\n",
        "#     for path in paths:\n",
        "#         if count ==5:\n",
        "#             break\n",
        "#         path = os.path.join(dir_path,path)\n",
        "#         with open(path,'r') as file:\n",
        "#                     data = file.read()\n",
        "#                     data = data.split()\n",
        "#                     for index, word in enumerate(data):\n",
        "#                         if word.isnumeric():\n",
        "#                             word = int(word)\n",
        "#                             changed_word = p.number_to_words(word)\n",
        "#                             data[index]= changed_word\n",
        "#                     new_data = ' '.join(data)\n",
        "                    \n",
        "#                     #Replacing Contractions with full words\n",
        "#                     #specific\n",
        "                    \n",
        "#                     new_data = re.sub(r\"won\\'t\", \"will not\", new_data)\n",
        "#                     new_data = re.sub(r\"can\\'t\", \"can not\", new_data)\n",
        "\n",
        "#                     # general\n",
        "#                     new_data = re.sub(r\"n\\'t\", \" not\", new_data)\n",
        "#                     new_data = re.sub(r\"\\'re\", \" are\", new_data)\n",
        "#                     new_data = re.sub(r\"\\'s\", \" is\", new_data)\n",
        "#                     new_data = re.sub(r\"\\'d\", \" would\", new_data)\n",
        "#                     new_data = re.sub(r\"\\'ll\", \" will\", new_data)\n",
        "#                     new_data = re.sub(r\"\\'t\", \" not\", new_data)\n",
        "#                     new_data = re.sub(r\"\\'ve\", \" have\", new_data)\n",
        "#                     new_data = re.sub(r\"\\'m\", \" am\", new_data)\n",
        "                    \n",
        "#                     #Removing Puntuation Marks\n",
        "#                     new_data = re.sub(r'[^\\w\\s]', '', new_data)\n",
        "#                     file.close()\n",
        "#         count+=1\n",
        "#         with open(path,'w') as file:\n",
        "#             file.write(new_data)\n",
        "#             file.close()\n",
        "    \n",
        "# dir_path = \"/home/ali/Desktop/Namal/Idrak/trump/wavs_text\"\n",
        "# cleaning_text_files(dir_path)\n",
        "    \n",
        "            \n",
        "# !pip3 install torchaudio==0.12.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XwKAgxp1DNjl"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "REcPDTZ0DNjl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu111/torch_stable.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ph7Ts036DNjm",
        "outputId": "55024b73-bf48-497a-8895-27e160458cf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4fgaFGLhDNjm",
        "outputId": "0099fc76-76bd-435d-dd39-394cc7950b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "torch.cuda.get_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Np_QeC7ADNjn",
        "outputId": "af157003-d2e1-4d7b-b3bb-db4a7c550231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "torch.cuda.memory_reserved()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qra9qNOaDNjn",
        "outputId": "3910395d-9ff4-46b0-e31c-dd7fc05c498e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "torch.cuda.memory_allocated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I-RVbZ-9DNjn",
        "outputId": "b38ec49b-7fd9-469b-d6e4-5ef9e1a155fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4f21365d05fb>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  waveform = torch.tensor(waveform)\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/transforms/_transforms.py:611: UserWarning: Argument 'onesided' has been deprecated and has no influence on the behavior of this module.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "# p1  =\"/home/ali/Desktop/Namal/Idrak/trump/tacotron2-master/wavs/1.wav\"\n",
        "\n",
        "\n",
        "\n",
        "dir_path = \"/content/drive/MyDrive/Idrak/full_wavs1\"\n",
        "paths = os.listdir(dir_path)\n",
        "paths = sorted(paths, key=lambda s: int(re.search(r'\\d+', s).group()))\n",
        "\n",
        "\n",
        "def audio_preprocessing(audio_file_path):\n",
        "    \n",
        "    metadata = torchaudio.info(audio_file_path)\n",
        "    waveform,sample_rate = torchaudio.load(audio_file_path)\n",
        "    # waveform,sample_rate = librosa.load(audio_file_path,sr=None)\n",
        "    waveform = waveform.mean(dim=0)\n",
        "   \n",
        "    waveform = torch.tensor(waveform)\n",
        "    n_fft = 1024\n",
        "    win_length = None\n",
        "    hop_length = 512\n",
        "    n_mels = 80\n",
        "\n",
        "    mel_spectrogram = T.MelSpectrogram(\n",
        "        sample_rate=sample_rate,\n",
        "        n_fft=n_fft,\n",
        "        win_length=win_length,\n",
        "        hop_length=hop_length,\n",
        "        center=True,\n",
        "        pad_mode=\"reflect\",\n",
        "        power=2.0,\n",
        "        norm=\"slaney\",\n",
        "        onesided=True,\n",
        "        n_mels=n_mels,\n",
        "        mel_scale=\"htk\",\n",
        "    )\n",
        "    melspec = mel_spectrogram(waveform)\n",
        "\n",
        "    return waveform,sample_rate,melspec\n",
        "\n",
        "\n",
        "melspecs = []\n",
        "melspec_lengths =[]\n",
        "melspec_times = []\n",
        "\n",
        "for idx,path in enumerate(paths[:100]):\n",
        "    audio_file_path = os.path.join(dir_path,path)\n",
        "    waveform,sample_rate,melspec = audio_preprocessing(audio_file_path)\n",
        "    melspecs.append(melspec)\n",
        "    melspec_lengths.append(torch.tensor(melspec.shape[1]))\n",
        "    \n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tQI9ZpJ0DNjo"
      },
      "outputs": [],
      "source": [
        "\n",
        "melspec_lengths = torch.stack(melspec_lengths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3YT1Pkp4DNjo",
        "outputId": "ddce2d82-6fcf-4efa-9d02-a9eac106c71b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2854, 2776, 2650, 2868, 1560, 1721, 3166,  783, 1649, 2587,  414,  518,\n",
              "        1892,  441,  941,  621, 1892, 2738,  248,  257,  847,  519,  603,  435,\n",
              "         609,  521, 1370, 1812, 1279,  623,  333,  949, 1304, 1477,  786, 1277,\n",
              "         789, 2002,  942, 2939,  185, 3007,  671,  349, 2510, 2398, 1117,  337,\n",
              "         779, 2251,  174,  506,  696, 1460, 1966,  931,  689,  692,  614, 1466,\n",
              "        1041,  948, 1360, 1021,  798,  505, 1196, 2233, 2591, 1825, 3265,  605,\n",
              "        1735,  344, 2994, 1709,  528, 1628,  872,  957, 1642, 1447, 1389, 2317,\n",
              "         876,  696,  411, 1541, 2828, 3261, 2938, 1122,  686, 2586, 1116, 2843,\n",
              "        1992, 1642, 2846, 2833])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "melspec_lengths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5R0yUBYjDNjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0ab3ce-e7f0-422a-ba26-2ed4f1720ad9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 80, 3265])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "for idx,tensor in enumerate(melspecs):\n",
        "    padding_req = melspec_lengths.max()-tensor.shape[1]\n",
        "    padded_tensor = torch.nn.functional.pad(tensor,(0,padding_req,0,0),mode='constant',value=0)\n",
        "    melspecs[idx] = padded_tensor\n",
        "\n",
        "melspecs = torch.stack(melspecs)\n",
        "melspecs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rqqXp32rDNjo"
      },
      "outputs": [],
      "source": [
        "melspecs = melspecs.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "melspecs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An3yNr0r6eL7",
        "outputId": "1e83204f-56b7-4a72-be81-170db71760f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 80, 3265])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HzpNQ9DaDNjp"
      },
      "outputs": [],
      "source": [
        "symbols = \"_-!'(),.:;? abcdefghijklmnopqrstuvwxyz\"\n",
        "\n",
        "look_up = {s: i for i, s in enumerate(symbols)}\n",
        "symbols = set(symbols)\n",
        "\n",
        "\n",
        "def text_to_sequence(text):\n",
        "    text = text.lower()\n",
        "    return [look_up[s] for s in text if s in symbols]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install deep_phonemizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFzut4hXYuYR",
        "outputId": "6719b4eb-8887-45fb-92dd-117bbd70b568"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deep_phonemizer in /usr/local/lib/python3.10/dist-packages (0.0.19)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from deep_phonemizer) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from deep_phonemizer) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from deep_phonemizer) (6.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from deep_phonemizer) (2.12.2)\n",
            "Requirement already satisfied: certifi>=2022.12.7 in /usr/local/lib/python3.10/dist-packages (from deep_phonemizer) (2022.12.7)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from deep_phonemizer) (0.40.0)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from deep_phonemizer) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->deep_phonemizer) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->deep_phonemizer) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->deep_phonemizer) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->deep_phonemizer) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->deep_phonemizer) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->deep_phonemizer) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.2.0->deep_phonemizer) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.2.0->deep_phonemizer) (16.0.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (3.4.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deep_phonemizer) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deep_phonemizer) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deep_phonemizer) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deep_phonemizer) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deep_phonemizer) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->deep_phonemizer) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->deep_phonemizer) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->deep_phonemizer) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->deep_phonemizer) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->deep_phonemizer) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.2.0->deep_phonemizer) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->deep_phonemizer) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->deep_phonemizer) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_4CEDQ9f_C8T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G9FKKAiHDNjp"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "dir_path = \"/content/drive/MyDrive/Idrak/full_wavs_text\"\n",
        "paths = os.listdir(dir_path)\n",
        "paths = sorted(paths, key=lambda s: int(re.search(r'\\d+', s).group()))\n",
        "bundle = torchaudio.pipelines.TACOTRON2_WAVERNN_PHONE_LJSPEECH\n",
        "\n",
        "processor = bundle.get_text_processor()\n",
        "\n",
        "text_tensors = []\n",
        "text_lengths  =[]\n",
        "with torch.inference_mode():\n",
        "    for path in paths[:100]:\n",
        "        text_file_path = os.path.join(dir_path,path)\n",
        "        file = open(text_file_path,'r')\n",
        "        text = file.read()\n",
        "        processed, lengths = processor(text)\n",
        "        text_tensors.append(processed)\n",
        "        text_lengths.append(lengths)\n",
        "        # print(processed,lengths)\n",
        "       \n",
        "# print(text_lengths,text_tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_pXe10yBDNjp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# padding the Tensors to the max_length tensor\n",
        "for idx,tensor in enumerate(text_tensors):\n",
        "    padding_req = max(text_lengths)-tensor.shape[1]\n",
        "    padded_tensor = torch.nn.functional.pad(tensor,(0,padding_req,0,0),mode='constant',value=0)\n",
        "    text_tensors[idx] = padded_tensor\n",
        "\n",
        "\n",
        "text_tensors = torch.stack(text_tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7tPo2ePADNjp",
        "outputId": "c4b8de35-433f-495a-f710-b6c639a5bcd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-26d9f8ffab4a>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  text_tensors = torch.tensor(text_tensors,dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "text_tensors = torch.tensor(text_tensors,dtype=torch.int32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9OfV38AUDNjp"
      },
      "outputs": [],
      "source": [
        "text_tensors = text_tensors.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rlYjSShjDNjq"
      },
      "outputs": [],
      "source": [
        "text_lengths = torch.stack(text_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "43HKgLiADNjq"
      },
      "outputs": [],
      "source": [
        "text_lengths= text_lengths.squeeze()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fKJM0MrGDNjq",
        "outputId": "05c1c4da-a085-443a-85e0-37a842d30e9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 80, 3265]) torch.Size([100]) torch.Size([100, 506]) torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "print(melspecs.shape,melspec_lengths.shape,text_tensors.shape,text_lengths.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xmRbEn1JDNjq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VtSiOPjWDNjq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "mel_train,mel_test,mel_length_train,mel_length_test,text_train,text_test,text_length_train,text_length_test  =train_test_split(melspecs,\n",
        "                                                                        melspec_lengths,\n",
        "                                                                       text_tensors,text_lengths,\n",
        "                                                            test_size=0.3, random_state=42            )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 8"
      ],
      "metadata": {
        "id": "yx8McS-z60Ld"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4pUbj0G8DNjq"
      },
      "outputs": [],
      "source": [
        "mel_train_data = DataLoader(mel_train,batch_size=batch) # tenosrs of Shape [80,28680]\n",
        "\n",
        "mel_length_train_data = DataLoader(mel_length_train,batch_size=batch) # Tensors of shape [,2]\n",
        "\n",
        "text_train_data  =DataLoader(text_train, batch)\n",
        "text_length_train_data = DataLoader(text_length_train,batch_size=batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "y6z8fJXdDNjr"
      },
      "outputs": [],
      "source": [
        "mel_test_data = DataLoader(mel_test,batch_size=batch) # tenosrs of Shape [80,28680]\n",
        "\n",
        "mel_length_test_data = DataLoader(mel_length_test,batch_size=batch) # Tensors of shape [,2]\n",
        "\n",
        "text_test_data  =DataLoader(text_test, batch_size=batch)\n",
        "text_length_test_data = DataLoader(text_length_test,batch_size=batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3g_B9hZDNjr"
      },
      "source": [
        "Setting Up The GPU Setting -- CUDA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "EZm2v6ebbPzb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "S5iyu7gbDNjs",
        "outputId": "faec8496-f282-4f2f-d6ee-77b47bc48927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112807936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from torchaudio.models import Tacotron2\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
        "\n",
        "# bundle = torchaudio.pipelines.TACOTRON2_WAVERNN_PHONE_LJSPEECH\n",
        "# tacotron2 = bundle./\n",
        "# Tacotron2.forward(tacotron2,text_tensors,text_lengths,melspecs,melspec_lengths)\n",
        "\n",
        "epochs =2\n",
        "model = Tacotron2()\n",
        "\n",
        "model  = model.to(device)\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "print(torch.cuda.memory_allocated())\n",
        "text_lengths.shape\n",
        "# model.forward(text_tensors,text_lengths,melspecs,melspec_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "4H40mMV3_SX0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yx8N4DHwDNjs",
        "outputId": "2d781d9e-4ec3-43c5-d87c-5775646e9cbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 80, 3265]) torch.Size([100]) torch.Size([100, 506]) torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "print(melspecs.shape,melspec_lengths.shape,text_tensors.shape,text_lengths.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "33BFUdHZDNjs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Create the optimizer\n",
        "mae_loss = torch.nn.MSELoss()\n",
        "stop_tokens_loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), # parameters of target model to optimize\n",
        "                            lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "AXdyXek2DNjs",
        "outputId": "6e30473d-4392-4dce-c31b-8f2b22471320",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125829120"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "torch.cuda.memory_reserved()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aknug1YIuxs",
        "outputId": "c0c1c4e0-4a4a-441e-b4b4-0217e026e5e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iR_dUHbDNjt"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "\n",
        "\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "\n",
        "import tqdm\n",
        "# torch.cuda.empty_cache()\n",
        "# gc.collect()\n",
        "model.train()\n",
        "\n",
        "accumulation_steps  = 4\n",
        "\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    count = 0\n",
        "    for mel_specs,mel_lens,text,text_lens in zip(mel_train_data,\n",
        "                                                 mel_length_train_data,\n",
        "                                                 text_train_data,\n",
        "                                                 text_length_train_data):\n",
        "        count+=1\n",
        "        # print(mel_specs.shape)\n",
        "        # print(mel_train_data)\n",
        "        stop_lst = [melspec[1] for melspec in mel_specs]\n",
        "        \n",
        "        stop_targets = torch.stack(stop_lst)\n",
        "        # print(stop_targets.shape)\n",
        "       \n",
        "        stop_targets  = stop_targets.to(device)\n",
        "        \n",
        "\n",
        "        text = text.to(device)\n",
        "        # print(torch.cuda.memory_allocated())\n",
        "        \n",
        "        text_lens = text_lens.to(device)\n",
        "        # print(torch.cuda.memory_allocated())\n",
        "\n",
        "        mel_specs = mel_specs.to(device)\n",
        "        # print(torch.cuda.memory_allocated())\n",
        "\n",
        "        mel_lens = mel_specs.to(device)\n",
        "        # print(torch.cuda.memory_allocated())\n",
        "\n",
        "        try:\n",
        "            pre_specs, post_specs, stop_tokens_pred,_ = model(text,text_lens,mel_specs,mel_lens)\n",
        "            \n",
        "        except RuntimeError as e:\n",
        "            \n",
        "            if \"CUDA out of memory\" in str(e):\n",
        "                # handle out of memory error\n",
        "                \n",
        "                \n",
        "                \n",
        "                pre_specs, post_specs, stop_tokens_pred,_ = model(text,text_lens,mel_specs,mel_lens)\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "      \n",
        "        \n",
        "        \n",
        "        mel_loss= mae_loss(pre_specs,post_specs) \n",
        "\n",
        "        stop_loss = stop_tokens_loss(stop_tokens_pred,stop_targets)\n",
        "        \n",
        "        \n",
        "        total_loss = mel_loss +stop_loss\n",
        "        total_loss.backward()\n",
        "        if count % accumulation_steps == 0:\n",
        "          optimizer.zero_grad()\n",
        "          optimizer.step()\n",
        "          count = 0\n",
        "    # model.eval()\n",
        "    # with torch.inference_mode():\n",
        "    #     for mel_specs,mel_lens,text,text_lens in zip(mel_test_data,\n",
        "    #                                                 mel_length_test_data,\n",
        "    #                                                 text_test_data,\n",
        "    #                                                 text_length_test_data):\n",
        "        \n",
        "    #         stop_lst = [melspec[1] for melspec in mel_specs]\n",
        "\n",
        "           \n",
        "        \n",
        "    #         stop_targets_test = torch.stack(stop_lst)\n",
        "\n",
        "    #         stop_targets_test  = stop_targets_test.to(device)\n",
        "        \n",
        "\n",
        "    #         text = text.to(device)\n",
        "    #         # print(torch.cuda.memory_allocated())\n",
        "            \n",
        "    #         text_lens = text_lens.to(device)\n",
        "    #         # print(torch.cuda.memory_allocated())\n",
        "\n",
        "    #         mel_specs = mel_specs.to(device)\n",
        "    #         # print(torch.cuda.memory_allocated())\n",
        "\n",
        "    #         mel_lens = mel_specs.to(device)\n",
        "    #         # print(torch.cuda.memory_allocated())\n",
        "\n",
        "    #         pre_specs, post_specs, stop_tokens_pred,_ = model(text,text_lens,mel_specs,mel_lens)\n",
        "    #         mel_loss_test= mae_loss(pre_specs,post_specs) \n",
        "\n",
        "    #         stop_loss_test = stop_tokens_loss(stop_tokens_pred,stop_targets_test)\n",
        "        \n",
        "        \n",
        "    #         test_loss = mel_loss_test +stop_loss_test\n",
        "        # put the model in evaluation mode for testing (inference)\n",
        "   \n",
        "        \n",
        "\n",
        "    \n",
        "    # torch.cuda.empty_cache()\n",
        "   \n",
        "    # # if epoch % 10 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    total_loss = total_loss.cpu()\n",
        "    train_loss_values.append(total_loss.detach().numpy())\n",
        "    # test_loss_values.append(test_loss.detach().numpy())\n",
        "    print(f\"Epoch: {epoch} |  Train Loss: {total_loss} | Test Loss \")\n",
        "    # del text,text_lens,mel_specs,mel_lens,stop_targets\n",
        "    # gc.collect()\n",
        "    # torch.cuda.empty_cache()\n",
        "    # torch.cuda.ipc_collect()\n",
        "        \n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "0JavVQJYDNjt",
        "outputId": "b25d6b8e-e9fd-4fbb-9188-688a91a0a290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "num_of_gpus = torch.cuda.device_count()\n",
        "print(num_of_gpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1j6FwRk-DNjt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "da7f3b9c-96b5-452d-84ea-c0cc62abc17b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      | 489998 KiB |   7758 MiB |  12926 GiB |  12926 GiB |\\n|       from large pool | 471222 KiB |   4717 MiB |  11876 GiB |  11875 GiB |\\n|       from small pool |  18776 KiB |   6106 MiB |   1050 GiB |   1050 GiB |\\n|---------------------------------------------------------------------------|\\n| Active memory         | 489998 KiB |   7758 MiB |  12926 GiB |  12926 GiB |\\n|       from large pool | 471222 KiB |   4717 MiB |  11876 GiB |  11875 GiB |\\n|       from small pool |  18776 KiB |   6106 MiB |   1050 GiB |   1050 GiB |\\n|---------------------------------------------------------------------------|\\n| Requested memory      | 485829 KiB |   7639 MiB |  12837 GiB |  12836 GiB |\\n|       from large pool | 467064 KiB |   4601 MiB |  11787 GiB |  11786 GiB |\\n|       from small pool |  18764 KiB |   6102 MiB |   1049 GiB |   1049 GiB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  10906 MiB |  10906 MiB |  10906 MiB |      0 B   |\\n|       from large pool |   4784 MiB |   4784 MiB |   4784 MiB |      0 B   |\\n|       from small pool |   6122 MiB |   6122 MiB |   6122 MiB |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory | 222705 KiB | 345338 KiB |  12661 GiB |  12660 GiB |\\n|       from large pool | 167754 KiB | 277799 KiB |  11513 GiB |  11513 GiB |\\n|       from small pool |  54951 KiB |  89956 KiB |   1147 GiB |   1147 GiB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     263    |   68875    |   10301 K  |   10300 K  |\\n|       from large pool |      53    |    3362    |     888 K  |     888 K  |\\n|       from small pool |     210    |   68797    |    9412 K  |    9412 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     263    |   68875    |   10301 K  |   10300 K  |\\n|       from large pool |      53    |    3362    |     888 K  |     888 K  |\\n|       from small pool |     210    |   68797    |    9412 K  |    9412 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |    3273    |    3273    |    3273    |       0    |\\n|       from large pool |     212    |     212    |     212    |       0    |\\n|       from small pool |    3061    |    3061    |    3061    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      90    |    8279    |    5011 K  |    5011 K  |\\n|       from large pool |      23    |      32    |     747 K  |     747 K  |\\n|       from small pool |      67    |    8256    |    4264 K  |    4264 K  |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fi-t4O2cDNjt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "d10Qr9T7DNjt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "IZHntyPHDNjt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "786b84c5ce3d49655503f1d8e6e861bce07ffe6b6c5a139b642d1f1b247a74fa"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}